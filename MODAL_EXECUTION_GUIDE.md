# Claidex Risk Score ‚Äî Modal Execution Guide

## What You Need to Run

This guide provides the exact commands to execute the Modal-based parallel risk score pipeline.

## Prerequisites Checklist

Before running, ensure you have:

- ‚úÖ Modal account (sign up at https://modal.com)
- ‚úÖ Neo4j instance accessible from the internet
  - Host/port accessible (not behind firewall)
  - Can handle 300+ concurrent connections
  - Recommended: `dbms.connector.bolt.thread_pool_max_size=500`
- ‚úÖ Postgres instance for results
  - Contains `providers`, `exclusions`, `payments_combined_v` tables
- ‚úÖ Python 3.11+ with pip

## Step-by-Step Execution

### 1. Install Dependencies (Local)

```bash
cd /Users/sahaj/Documents/Projects/Claidex

# Install Modal CLI + dependencies
pip install -r etl/compute/requirements-modal.txt
```

### 2. Authenticate with Modal

```bash
modal setup
```

This opens a browser for authentication. Follow the prompts and log in.

### 3. Create Neo4j Secret

Modal workers run in the cloud and must connect to a Neo4j instance reachable from the internet. Use **Neo4j Aura** (or another cloud instance); `localhost` will not work from Modal.

Use the **same** Neo4j values as in your `.env` so Modal workers connect to the same Aura instance. For **Aura**, the username is usually the **instance ID** (e.g. `5c8d6587`), not `neo4j`.

```bash
# Copy from your .env (replace with your actual password)
modal secret create claidex-neo4j \
    NEO4J_URI="neo4j+s://5c8d6587.databases.neo4j.io" \
    NEO4J_USER="5c8d6587" \
    NEO4J_PASSWORD="your-actual-aura-password"
```

**Aura database:** For Aura, the database name is the instance ID (e.g. `5c8d6587`), not `neo4j`. The code **auto-detects** this from `NEO4J_URI` when the host is `*.databases.neo4j.io`, so you do **not** need to set `NEO4J_DATABASE` in the secret unless you use a different database. To set it explicitly:

```bash
modal secret create claidex-neo4j \
    NEO4J_URI="neo4j+s://5c8d6587.databases.neo4j.io" \
    NEO4J_USER="5c8d6587" \
    NEO4J_PASSWORD="your-password" \
    NEO4J_DATABASE="5c8d6587"
```

If the secret already exists, update it in the [Modal dashboard](https://modal.com/secrets) or recreate with the command above (overwrites).

### 4. Export Data from Postgres

```bash
# This reads from your local/Docker Postgres and exports to parquet files
python etl/compute/prepare_modal_data.py

# Expected output:
# [1/3] Exporting providers...
#   ‚úì 1,788,105 providers
# [2/3] Exporting exclusions...
#   ‚úì 12,345 exclusion records
# [3/3] Exporting payments...
#   ‚úì 45,678,901 payment rows
```

**Troubleshooting:**
- If connection fails, check `POSTGRES_URL` in `.env`
- For Docker Postgres, use port 5433 (not 5432)
- If too large, use `--years 3` to export only recent years

### 5. Create Modal Volume

```bash
modal volume create claidex-data
```

If already exists, you'll see: "Volume claidex-data already exists"

### 6. Upload Data to Modal Volume

The volume is mounted at `/data` in containers, so upload to the volume root (files will appear at `/data/<filename>`):

```bash
# Upload providers (usually ~500MB)
modal volume put claidex-data \
    ./data/modal_input/providers.parquet \
    providers.parquet

# Upload payments (usually 1-5GB, may take a few minutes)
modal volume put claidex-data \
    ./data/modal_input/payments_combined.parquet \
    payments_combined.parquet

# Upload exclusions (usually <10MB)
modal volume put claidex-data \
    ./data/modal_input/exclusions.parquet \
    exclusions.parquet
```

**Note:** Large files may take 5-10 minutes to upload. Modal shows progress.

**Verify upload:**
```bash
modal volume ls claidex-data /
```

Expected output:
```
providers.parquet
payments_combined.parquet
exclusions.parquet
```

### 7. Test Modal (verify Neo4j / Aura before full run)

To confirm the Modal secret and Neo4j Aura database are correct, run **only the first 2 batches** (no DB upsert):

```bash
modal run etl/compute/claidex_modal.py \
    --postgres-url "postgresql://claidex:Claidex2026-docker@localhost:5433/claidex" \
    --max-batches 2 \
    --no-upsert-to-db
```

- You should see 2 batches complete **without** `Database.DatabaseNotFound` or `database 'neo4j' does not exist`.
- If you see those errors, the Aura database name was wrong; the code now auto-detects it from the URI (instance ID) when using `*.databases.neo4j.io`. Ensure your Modal secret `claidex-neo4j` has `NEO4J_URI`, `NEO4J_USER`, and `NEO4J_PASSWORD` set (and optionally `NEO4J_DATABASE`).

### 8. Run the Full Pipeline

```bash
# Get your Postgres connection URL from .env
# For local Docker: postgresql://claidex:Claidex2026-docker@localhost:5433/claidex
# For Neon: use NEON_PROVIDERS_URL (prefer pooled URL from Neon Console for connection limits)

modal run etl/compute/claidex_modal.py \
    --postgres-url "postgresql://claidex:Claidex2026-docker@localhost:5433/claidex" \
    --batch-size 1000 \
    --upsert-to-db
```

**Alternative (use .env automatically):**
```bash
# If POSTGRES_URL or NEON_PROVIDERS_URL is set in .env:
modal run etl/compute/claidex_modal.py
```

**To run in background (detached):**
```bash
modal run --detach etl/compute/claidex_modal.py \
    --postgres-url "postgresql://..."
```

### 8b. Run Merge Only (chunks already on volume)

If all batch chunks are already on the Modal volume (e.g. a previous run finished batches but timed out during merge), run **only** the merge step: concatenate chunks, global calibration, and optional Postgres upsert.

**Option 1 ‚Äî Script (recommended):**
```bash
# From repo root; uses POSTGRES_URL or NEON_PROVIDERS_URL from .env
./scripts/run_merge_only.sh

# With explicit Postgres URL
./scripts/run_merge_only.sh "postgresql://claidex:Claidex2026-docker@localhost:5433/claidex"

# Merge only, no DB upsert
./scripts/run_merge_only.sh --no-upsert
```

**Option 2 ‚Äî Modal directly:**
```bash
modal run etl/compute/claidex_modal.py --merge-only \
  --postgres-url "postgresql://claidex:Claidex2026-docker@localhost:5433/claidex" \
  --upsert-to-db
```

Merge has a 2-hour timeout and reads chunks in batches of 1000 files, so it can complete even with 9k+ chunk files.

**Expected Output:**
```
================================================================================
Claidex Risk Score ‚Äî Modal Parallel Batch Compute
================================================================================
Batch size: 1000
Postgres URL: postgresql://claidex:***@localhost:5433/claidex
Upsert to DB: True

Loading NPI list from volume...
Total NPIs: 1,788,105

Total batches: 1,789 (batch_size=1000)

Launching parallel batch processing on Modal...
  ‚Üí Up to 300 containers will run concurrently
  ‚Üí Each batch processes ~1000 NPIs with 1 batched Neo4j query
  ‚Üí Expected completion: ~5-15 minutes

  ‚Üí 347/1789 batches complete
  ‚Üí 682/1789 batches complete
  ‚Üí 1234/1789 batches complete
  ‚Üí 1789/1789 batches complete

All 1789 batches complete!

Merging results and performing global calibration...
[Merge] Reading all chunk files...
[Merge] Found 1789 chunk files
[Merge] Concatenated 1,788,105 rows
[Merge] Performing global PERCENT_RANK calibration...
[Merge] Final merged file: /data/claidex_results_final.parquet (1,788,105 rows)
[Merge] Upserting to Postgres provider_risk_scores...
[Merge] Upsert complete

================================================================================
Done! Results:
  ‚Üí Modal Volume: /data/claidex_results_final.parquet
  ‚Üí Postgres table: provider_risk_scores

Download with:
  mkdir -p results && modal volume get claidex-data claidex_results_final.parquet ./results/final.parquet
================================================================================
```

### 9. Monitor Progress (Optional)

While running, monitor at: https://modal.com/apps

You'll see:
- Real-time logs from each container
- Progress bar for batch completion
- Any errors/retries

### 10. Download Results (Optional)

```bash
# Create results directory
mkdir -p results

# Download final parquet file (path is at volume root, not /data/...)
modal volume get claidex-data \
    claidex_results_final.parquet \
    ./results/final.parquet
```

**Note:** Results are already in your Postgres `provider_risk_scores` table if `--upsert-to-db` was used.

### 11. Validate Results (Optional but Recommended)

```bash
# Compare Modal results against local computation on a sample
python etl/compute/validate_modal_results.py \
    --modal-results ./results/final.parquet \
    --from-db \
    --sample 100
```

Expected output:
```
================================================================================
Validation Results
================================================================================

Total NPIs compared:            100
Identical (< 0.001):             98 (98.0%)

Missing in Modal:                 0
Missing in Local:                 0

Score Differences:
  Max difference:             0.0234
  Mean difference:            0.0012
  Median difference:          0.0005

Component Max Differences:
  Billing:                    0.0156
  Ownership:                  0.0089
  Trajectory:                 0.0123

‚úì PASS ‚Äî Modal results match local within acceptable bounds
  98.0% identical, max diff 0.0234
================================================================================
```

## Quick Reference Commands

### One-Time Setup
```bash
pip install -r etl/compute/requirements-modal.txt
modal setup
modal secret create claidex-neo4j NEO4J_URI=... NEO4J_USER=... NEO4J_PASSWORD=...
modal volume create claidex-data
```

### Every Run (After Data Changes)
```bash
# 1. Export fresh data
python etl/compute/prepare_modal_data.py

# 2. Upload to Modal
modal volume put claidex-data ./data/modal_input/providers.parquet /data/providers.parquet
modal volume put claidex-data ./data/modal_input/payments_combined.parquet /data/payments_combined.parquet
modal volume put claidex-data ./data/modal_input/exclusions.parquet /data/exclusions.parquet

# 3. Run pipeline
modal run etl/compute/claidex_modal.py --postgres-url "postgresql://..."
```

### Scheduled Runs (No Fresh Data Export)
```bash
# If data in Modal volume is current, just re-run:
modal run etl/compute/claidex_modal.py
```

## Common Issues and Solutions

### "Neo4j ServiceUnavailable" or "Connection refused"

**Problem:** Modal containers can't reach your Neo4j instance

**Solutions:**
1. **If using Docker Neo4j on localhost:**
   - Docker containers are not accessible from Modal (which runs in the cloud)
   - Deploy Neo4j to a cloud instance (AWS, GCP, Azure) or use Neo4j AuraDB
   - Alternative: Set up SSH tunnel or VPN (advanced)

2. **If using cloud Neo4j:**
   - Ensure firewall allows incoming connections from any IP
   - Check Neo4j logs for connection errors
   - Test connection: `cypher-shell -a bolt://your-host:7687 -u neo4j -p password`

### "FileNotFoundError: /data/providers.parquet"

**Problem:** Data not uploaded to Modal volume

**Solution:**
```bash
# Verify volume contents
modal volume ls claidex-data /data/

# If empty, re-upload:
python etl/compute/prepare_modal_data.py
modal volume put claidex-data ./data/modal_input/*.parquet /data/
```

### "OOM (Out of Memory)" or Container Restarts

**Problem:** Insufficient memory for batch processing

**Solution:**
Edit `etl/compute/claidex_modal.py` line 94:
```python
memory=8192,  # Increase from 4096 to 8192 (8GB)
```

Or reduce batch size:
```bash
modal run etl/compute/claidex_modal.py --batch-size 500
```

### "Timeout" on Neo4j Queries

**Problem:** Neo4j queries taking >15 minutes per batch

**Solutions:**
1. Reduce batch size:
   ```bash
   modal run etl/compute/claidex_modal.py --batch-size 500
   ```

2. Add Neo4j indexes:
   ```cypher
   CREATE INDEX FOR (ce:CorporateEntity) ON (ce.name);
   CREATE INDEX FOR (p:Provider) ON (p.name);
   ```

3. Increase timeout in `claidex_modal.py` line 92:
   ```python
   timeout=1800,  # Increase from 900 to 1800 (30 min)
   ```

### "Connection to host.docker.internal failed" (Postgres)

**Problem:** Using localhost Postgres URL from Docker environment

**Solution:**
- If Postgres is in Docker on your local machine, Modal can't reach it
- Use Neon cloud Postgres instead:
  ```bash
  modal run etl/compute/claidex_modal.py \
      --postgres-url "$NEON_PROVIDERS_URL"
  ```
- Or deploy Postgres to a cloud instance accessible from Modal

## Cost Tracking

Check your Modal usage at: https://modal.com/usage

Expected costs per run:
- **1.78M NPIs:** ~$2.50
- **500K NPIs:** ~$0.70
- **100K NPIs:** ~$0.15

Modal includes $30/month free credit (covers ~12 full runs).

## Cleanup

### Remove Old Output Chunks (Save Space)

```bash
# After successful run, clean up intermediate chunks
modal volume rm claidex-data /data/output_chunks/
```

### Delete Volume (Rare)

```bash
# Only if you want to start fresh
modal volume delete claidex-data
```

**Warning:** This deletes all uploaded data. You'll need to re-upload.

## Next Steps

1. ‚úÖ **First run complete?** Verify results in `provider_risk_scores` table
2. üìä **Validate accuracy:** Run `validate_modal_results.py` on sample
3. ‚öôÔ∏è **Optimize performance:** Tune batch size and concurrency
4. üîÑ **Automate:** Set up scheduled runs (see `MODAL_SETUP.md`)
5. üìà **Scale:** Process incremental updates for daily/weekly refreshes

## Support and Documentation

- **Quick Reference:** `etl/compute/QUICKSTART_MODAL.md`
- **Detailed Setup:** `etl/compute/MODAL_SETUP.md`
- **Implementation Details:** `etl/compute/MODAL_IMPLEMENTATION_SUMMARY.md`
- **Modal Platform Docs:** https://modal.com/docs
- **Original Local Script:** `etl/compute/risk_scores.py` (still works!)

## Summary

**What you just did:**
- ‚úÖ Deployed a parallel risk score pipeline to Modal
- ‚úÖ Processed 1.78M NPIs in ~5-15 minutes (vs. 25-100 hours local)
- ‚úÖ Reduced Neo4j queries from 1.78M to 1,789 via batching
- ‚úÖ Achieved ~500-1200√ó speedup with identical results

**Cost: ~$2.50 per run** (vs. $5-40 for equivalent EC2/local compute)

**Ready to run again?**

```bash
modal run etl/compute/claidex_modal.py
```

That's it! üöÄ
